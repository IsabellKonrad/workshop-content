{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow on GPU\n",
    "\n",
    "Notebook by [Aaron Berk](http://asberk.ca) for the 2017 [BC Data Science workshop](http://workshop.bcdata.ca)\n",
    "\n",
    "## Import `tensorflow-gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tensorflow devices\n",
    "\n",
    "We can check which devices tensorflow has access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "for ldp in device_lib.list_local_devices():\n",
    "    print(ldp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we can't see much because we're not on a GPU, but normally the output might look something like\n",
    "\n",
    "    name: \"/cpu:0\"\n",
    "    device_type: \"CPU\"\n",
    "    memory_limit: 268435456\n",
    "    locality {\n",
    "    }\n",
    "    incarnation: 3621252685137100441\n",
    "    \n",
    "    name: \"/gpu:0\"\n",
    "    device_type: \"GPU\"\n",
    "    memory_limit: 11332668621\n",
    "    locality {\n",
    "      bus_id: 1\n",
    "    }\n",
    "    incarnation: 18377748191823123760\n",
    "    physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
    "\n",
    "If we're just interested in what the name of the gpu is, we can wrap the code in a getter function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there *were* a GPU, we'd see the following as the output.\n",
    "\n",
    "    ['/gpu:0']\n",
    "\n",
    "## Device placement\n",
    "\n",
    "We can either rely on default device placement or explicit device placement. Notice that `allow_soft_placement` generally improves efficiency — because we only send taxing stuff to the GPU, and do the \"small\" stuff on the CPU. \n",
    "\n",
    "### Default device placement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "sess = tf.Session(config=config)\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual device placement\n",
    "\n",
    "We can manually select the device on which we want to perform a computation using the syntax structure below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    aa = tf.constant([1., 2., 3., 4., 5., 6.], shape=[2,3], name='aa')\n",
    "    bb = tf.constant([1., 2., 3., 4., 5., 6.], shape=[3,2], name='bb')\n",
    "cc = tf.matmul(aa, bb)\n",
    "print(sess.run(cc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

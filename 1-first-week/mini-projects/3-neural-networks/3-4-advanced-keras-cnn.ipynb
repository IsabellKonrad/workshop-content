{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs in `keras`\n",
    "\n",
    "Notebook by [Aaron Berk](http://asberk.ca) for the 2017 [BC Data Science workshop](http://workshop.bcdata.ca).\n",
    "\n",
    "In this tutorial notebook, we will demonstrate how to construct a CNN model in keras for recognizing hand-written digits. We leave it as an exercise to the reader to combine the material from the previous 3 notebooks in order to complete the training and evaluation of the constructed CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras` has several options for convolutional layers. Since we're working with images, we'll be using a `Conv2D` layer. Ã€ la standard machine learning practice, we'll also be using max pooling in order to aggregate our data (and decrease the dimension). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the method that imports the MNIST data set, and a method to convert the `y` data to categorical type (one-hot encoding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `classification_report` and `confusion_matrix` in order to display the testing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary definitions\n",
    "\n",
    "To construct our CNN, we'll be chaining together a bunch of convolutional layers, and a bunch of max-pooling layers: $$\n",
    "\\mathrm{data} \\to \\mathrm{Conv2D} \\to \\mathrm{MaxPool2D} \\to \\mathrm{Conv2D} \\to \\mathrm{MaxPool2D} \\to \\mathrm{Conv2D} \\to \\mathrm{MaxPool2D} \\to \\cdots\n",
    "$$\n",
    "Therefore, it will be easiest if we can define a set of functions in order to speed up the construction of our model. Building a CNN in `keras` is very similar to building a dense network in `keras`, but uses different kinds of layers.\n",
    "\n",
    "* `Conv2D` takes as input a number of `filters`, a `tuple` for the `kernel_size`, an `activation` function, a `stride` and a `padding`. For all of our `Conv2D` layers, we will be using `kernel_size=(3,3)`, `activation='relu'`, and `padding='same'`.\n",
    "* `MaxPool2D` takes as input a `pool_size` and a `padding`. We will use a standard `(2,2)` and `'same'` for these, respectively.\n",
    "\n",
    "To combine the two together, we can create a helper function called `convMP` which performs convolution and then max-pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reluConv2d(x, filters=16):\n",
    "    return Conv2D(filters=filters, kernel_size=(3,3), \n",
    "                  activation='relu', padding='same')(x)\n",
    "\n",
    "def mp2d(x):\n",
    "    return MaxPooling2D(pool_size=(2,2), \n",
    "                        padding='same')(x)\n",
    "\n",
    "def convMP(x, filters=16):\n",
    "    return mp2d(reluConv2d(x, filters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28,28,1))\n",
    "x = convMP(input_img)\n",
    "x = convMP(x)\n",
    "x = convMP(x)\n",
    "x = Flatten()(x)\n",
    "final_cnn = Dense(10, activation='softmax')(x)\n",
    "\n",
    "digits_cnnclf = Model(input_img, final_cnn, name='cnnClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits_cnnclf.compile(optimizer='adadelta',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['mse', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_1h = to_categorical(y_train)\n",
    "y_test_1h = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "1. `fit` the model to the **training data** using a `validation_split` of `.2` and 10 epochs. Remember to `shuffle` the data!  \n",
    "2. Evaluate the model **on the test data**. Report the accuracy.  \n",
    "3. Display a classification report for the **test** data.  \n",
    "4. What is precision? recall? support?  \n",
    "5. Plot a confusion matrix, using the *inferno* colormap.  \n",
    "6. What is the total number of *trainable parameters* the model has? How many in each layer? Are there more or fewer parameters than in the previous model?\n",
    "7. Save the your CNN model. In a new notebook, load your *simple model* and your *CNN model*. On which entries of the testing data do the two models differ in their predicitions? Visualize these images using `matplotlib`. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

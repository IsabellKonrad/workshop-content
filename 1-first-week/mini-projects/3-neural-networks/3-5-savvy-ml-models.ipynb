{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced machine learning\n",
    "\n",
    "Notebook by [Aaron Berk](http://asberk.ca) for the 2017 BC Data Science Workshop. Material modified from the [Keras blog](https://blog.keras.io).\n",
    "\n",
    "In this tutorial notebook, we will cover some \"fancy\" methods for doing machine learning using `keras` in python. In the first example, we'll build and train a CNN that can discriminate between cats and dogs, using a Kaggle competition data set. In other sections, we will include links or motivating material for other advanced ML-type projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ImageDataGenerator` function is going to allow us to grab data from a directory, and inject a randomly transformed version into our model for training. The major advantage for this is that we will not have to load in all of the data manually (it wouldn't even fit in memory!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial was taken from the Keras blog: [Power image classifier using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html). We've reimplemented part of it here for you to explore with. That data for this project is taken from the Kaggle [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) competition data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reluConv2d(x, filters=32):\n",
    "    return Conv2D(filters=filters, kernel_size=(3,3), \n",
    "                  activation='relu', padding='same')(x)\n",
    "\n",
    "def mp2d(x):\n",
    "    return MaxPooling2D(pool_size=(2,2), \n",
    "                        padding='same')(x)\n",
    "\n",
    "def convMP(x, filters=32):\n",
    "    return mp2d(reluConv2d(x, filters))\n",
    "\n",
    "def conv2dense(x, filters=64, dropout=None):\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(filters, activation='relu')(x)\n",
    "    if dropout is None:\n",
    "        return x\n",
    "    else:\n",
    "        return Dropout(dropout)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = Input(shape=(150,150,3))\n",
    "x = convMP(input_img)\n",
    "x = convMP(x)\n",
    "x = convMP(x, 64)\n",
    "x = conv2dense(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(input_img, output, name='CatDogClf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching the data\n",
    "\n",
    "The image data we will use is 2002 training images and 800 validation images from the training set of the Dogs vs. Cats data set.  This data is stored in `~/data/catsdogs/`. In order to access this data, we will use Keras's `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True,\n",
    "                                   shear_range=0.2,zoom_range=0.2)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '~/data/catsdogs/train/',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '~/data/catsdogs/validation/',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=2002 // batch_size,\n",
    "                    epochs=15,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('CatDogClf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoders\n",
    "\n",
    "Check out [this tutorial](https://blog.keras.io/building-autoencoders-in-keras.html) if you're interested in auto-encoders.\n",
    "\n",
    "An effective auto-encoder should act as an approximate identity on elements from the data distribution. They are composed of an encoder and a decoder that transform data to (respectively, from) a compressed representation. In this way they can be used to efficiently represent a distribution of objects (*e.g.*, the distribution of 28 x 28 handwritten digits). \n",
    "\n",
    "## Text-processing stuff\n",
    "\n",
    "If you've tackled everything above, come hang out with me during the problem solving session and we can hack on some machine learning and `nltk` stuff using the [UBC Library Open Collections API](https://open.library.ubc.ca/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
